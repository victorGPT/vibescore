===== test/auto-retry.test.js
const assert = require('node:assert/strict');
const os = require('node:os');
const path = require('node:path');
const fs = require('node:fs/promises');
const { test } = require('node:test');

const { cmdSync } = require('../src/commands/sync');

test('sync --auto schedules retry when throttled and pending', async () => {
  const tmp = await fs.mkdtemp(path.join(os.tmpdir(), 'vibescore-auto-retry-'));
  const prevHome = process.env.HOME;
  const prevCodexHome = process.env.CODEX_HOME;
  const prevNoSpawn = process.env.VIBESCORE_AUTO_RETRY_NO_SPAWN;

  try {
    process.env.HOME = tmp;
    process.env.CODEX_HOME = path.join(tmp, '.codex');
    process.env.VIBESCORE_AUTO_RETRY_NO_SPAWN = '1';

    const trackerDir = path.join(tmp, '.vibescore', 'tracker');
    await fs.mkdir(trackerDir, { recursive: true });
    await fs.mkdir(process.env.CODEX_HOME, { recursive: true });

    await fs.writeFile(
      path.join(trackerDir, 'config.json'),
      JSON.stringify({ baseUrl: 'https://example.invalid', deviceToken: 'token', deviceId: 'device' }, null, 2) + '\n',
      'utf8'
    );

    const queueLine = JSON.stringify({
      hour_start: '2025-12-23T00:00:00.000Z',
      input_tokens: 1,
      cached_input_tokens: 0,
      output_tokens: 0,
      reasoning_output_tokens: 0,
      total_tokens: 1
    });
    await fs.writeFile(path.join(trackerDir, 'queue.jsonl'), queueLine + '\n', 'utf8');
    await fs.writeFile(path.join(trackerDir, 'queue.state.json'), JSON.stringify({ offset: 0 }) + '\n', 'utf8');

    const nextAllowedAtMs = Date.now() + 60_000;
    await fs.writeFile(
      path.join(trackerDir, 'upload.throttle.json'),
      JSON.stringify({ version: 1, lastSuccessMs: 0, nextAllowedAtMs, backoffUntilMs: 0, backoffStep: 0 }, null, 2) + '\n',
      'utf8'
    );

    await cmdSync(['--auto']);

    const retryRaw = await fs.readFile(path.join(trackerDir, 'auto.retry.json'), 'utf8');
    const retry = JSON.parse(retryRaw);

    assert.ok(Number.isFinite(retry.retryAtMs), 'retryAtMs should be set');
    assert.ok(retry.retryAtMs >= nextAllowedAtMs, 'retryAtMs should be at or after nextAllowedAtMs');
    assert.equal(retry.reason, 'throttled');
    assert.equal(retry.pendingBytes > 0, true);
  } finally {
    if (prevHome === undefined) delete process.env.HOME;
    else process.env.HOME = prevHome;
    if (prevCodexHome === undefined) delete process.env.CODEX_HOME;
    else process.env.CODEX_HOME = prevCodexHome;
    if (prevNoSpawn === undefined) delete process.env.VIBESCORE_AUTO_RETRY_NO_SPAWN;
    else process.env.VIBESCORE_AUTO_RETRY_NO_SPAWN = prevNoSpawn;
    await fs.rm(tmp, { recursive: true, force: true });
  }
});

===== test/dashboard-render-order.test.js
const test = require("node:test");
const assert = require("node:assert/strict");
const fs = require("node:fs");
const path = require("node:path");

test("DashboardPage declares timeZone before use in range computation", () => {
  const filePath = path.join(
    __dirname,
    "..",
    "dashboard",
    "src",
    "pages",
    "DashboardPage.jsx"
  );
  const src = fs.readFileSync(filePath, "utf8");
  const timeZoneDeclIndex = src.search(/\b(const|let)\s+timeZone\b/);
  const rangeUseIndex = src.indexOf("getRangeForPeriod(");

  assert.ok(timeZoneDeclIndex !== -1, "timeZone declaration not found");
  assert.ok(rangeUseIndex !== -1, "getRangeForPeriod usage not found");
  assert.ok(
    timeZoneDeclIndex < rangeUseIndex,
    "timeZone should be declared before getRangeForPeriod call"
  );
});

===== test/details-sort.test.js
const assert = require("node:assert/strict");
const { test } = require("node:test");

test("sortDetailRows sorts day/hour/month keys by time", async () => {
  const mod = await import("../dashboard/src/lib/detail-sort.js");
  const sortDetailRows = mod.sortDetailRows;

  const dayRows = [
    { day: "2025-12-22", total_tokens: 10 },
    { day: "2025-12-23", total_tokens: 5 },
  ];
  const dayDesc = sortDetailRows(dayRows, { key: "day", dir: "desc" });
  assert.equal(dayDesc[0].day, "2025-12-23");
  const dayAsc = sortDetailRows(dayRows, { key: "day", dir: "asc" });
  assert.equal(dayAsc[0].day, "2025-12-22");

  const hourRows = [
    { hour: "2025-12-23T00:00:00Z", total_tokens: 1 },
    { hour: "2025-12-23T12:30:00Z", total_tokens: 2 },
  ];
  const hourDesc = sortDetailRows(hourRows, { key: "hour", dir: "desc" });
  assert.equal(hourDesc[0].hour, "2025-12-23T12:30:00Z");

  const monthRows = [
    { month: "2025-11", total_tokens: 1 },
    { month: "2025-12", total_tokens: 2 },
  ];
  const monthDesc = sortDetailRows(monthRows, { key: "month", dir: "desc" });
  assert.equal(monthDesc[0].month, "2025-12");
});

===== test/diagnostics.test.js
const assert = require('node:assert/strict');
const os = require('node:os');
const path = require('node:path');
const fs = require('node:fs/promises');
const { test } = require('node:test');

const { cmdDiagnostics } = require('../src/commands/diagnostics');

test('diagnostics redacts device token and home paths', async () => {
  const tmp = await fs.mkdtemp(path.join(os.tmpdir(), 'vibescore-diagnostics-'));
  const prevHome = process.env.HOME;
  const prevCodexHome = process.env.CODEX_HOME;
  const prevWrite = process.stdout.write;

  try {
    process.env.HOME = tmp;
    process.env.CODEX_HOME = path.join(tmp, '.codex');

    const trackerDir = path.join(tmp, '.vibescore', 'tracker');
    await fs.mkdir(trackerDir, { recursive: true });
    await fs.mkdir(process.env.CODEX_HOME, { recursive: true });

    const secret = 'super_secret_device_token';
    await fs.writeFile(
      path.join(trackerDir, 'config.json'),
      JSON.stringify(
        {
          baseUrl: 'https://example.invalid',
          deviceToken: secret,
          deviceId: '11111111-1111-1111-1111-111111111111',
          installedAt: '2025-12-19T00:00:00.000Z'
        },
        null,
        2
      ) + '\n',
      'utf8'
    );

    await fs.writeFile(
      path.join(process.env.CODEX_HOME, 'config.toml'),
      `notify = ["/usr/bin/env", "node", "${path.join(tmp, '.vibescore', 'bin', 'notify.cjs')}"]\n`,
      'utf8'
    );

    const retryAtMs = Date.now() + 60_000;
    await fs.writeFile(
      path.join(trackerDir, 'auto.retry.json'),
      JSON.stringify(
        {
          version: 1,
          retryAtMs,
          retryAt: new Date(retryAtMs).toISOString(),
          reason: 'throttled',
          pendingBytes: 123,
          scheduledAt: '2025-12-23T00:00:00.000Z',
          source: 'auto'
        },
        null,
        2
      ) + '\n',
      'utf8'
    );

    let out = '';
    process.stdout.write = (chunk, enc, cb) => {
      out += typeof chunk === 'string' ? chunk : chunk.toString(enc || 'utf8');
      if (typeof cb === 'function') cb();
      return true;
    };

    await cmdDiagnostics([]);

    assert.ok(!out.includes(secret), 'expected device token to be redacted');
    assert.ok(!out.includes(tmp), 'expected home path to be redacted');

    const data = JSON.parse(out);
    assert.equal(data?.config?.device_token, 'set');
    assert.equal(typeof data?.paths?.codex_home, 'string');
    assert.ok(String(data.paths.codex_home).startsWith('~'));
    assert.equal(data?.auto_retry?.reason, 'throttled');
    assert.equal(data?.auto_retry?.pending_bytes, 123);
    assert.equal(data?.auto_retry?.next_retry_at, new Date(retryAtMs).toISOString());
  } finally {
    process.stdout.write = prevWrite;
    if (prevHome === undefined) delete process.env.HOME;
    else process.env.HOME = prevHome;
    if (prevCodexHome === undefined) delete process.env.CODEX_HOME;
    else process.env.CODEX_HOME = prevCodexHome;
    await fs.rm(tmp, { recursive: true, force: true });
  }
});

===== test/edge-functions.test.js
const assert = require('node:assert/strict');
const { test, beforeEach, afterEach } = require('node:test');

const SERVICE_ROLE_KEY = 'srk_test_123';
const ANON_KEY = 'anon_test_123';
const BASE_URL = 'http://insforge:7130';

function setDenoEnv(env) {
  globalThis.Deno = {
    env: {
      get(key) {
        return Object.prototype.hasOwnProperty.call(env, key) ? env[key] : undefined;
      }
    }
  };
}

function createServiceDbMock() {
  const inserts = [];
  const updates = [];
  const selects = [];

  function from(table) {
    return {
      insert: async (rows) => {
        inserts.push({ table, rows });
        return { error: null };
      },
      update: (values) => ({
        eq: async (col, value) => {
          updates.push({ table, values, where: { col, value } });
          return { error: null };
        }
      }),
      select: (columns) => {
        const q = { table, columns, filters: [] };
        selects.push(q);
        return {
          eq: (col, value) => {
            q.filters.push({ op: 'eq', col, value });
            return {
              in: async (inCol, values) => {
                q.filters.push({ op: 'in', col: inCol, value: values });
                return { data: [], error: null };
              },
              maybeSingle: async () => ({ data: null, error: null })
            };
          }
        };
      }
    };
  }

  return {
    db: { from },
    inserts,
    updates,
    selects
  };
}

const ORIGINAL_DENO = globalThis.Deno;
const ORIGINAL_CREATE_CLIENT = globalThis.createClient;
const ORIGINAL_FETCH = globalThis.fetch;

beforeEach(() => {
  setDenoEnv({
    SERVICE_ROLE_KEY,
    INSFORGE_INTERNAL_URL: BASE_URL,
    ANON_KEY
  });
});

afterEach(() => {
  if (ORIGINAL_DENO === undefined) delete globalThis.Deno;
  else globalThis.Deno = ORIGINAL_DENO;

  if (ORIGINAL_CREATE_CLIENT === undefined) delete globalThis.createClient;
  else globalThis.createClient = ORIGINAL_CREATE_CLIENT;

  if (ORIGINAL_FETCH === undefined) delete globalThis.fetch;
  else globalThis.fetch = ORIGINAL_FETCH;
});

test('vibescore-device-token-issue works without serviceRoleKey (user mode)', async () => {
  setDenoEnv({
    INSFORGE_INTERNAL_URL: BASE_URL,
    ANON_KEY
  });

  const fn = require('../insforge-functions/vibescore-device-token-issue');

  const calls = [];
  const db = createServiceDbMock();
  const userId = '11111111-1111-1111-1111-111111111111';
  const userJwt = 'user_jwt_test';

  globalThis.createClient = (args) => {
    calls.push(args);

    if (args && args.edgeFunctionToken === userJwt) {
      return {
        auth: {
          getCurrentUser: async () => ({ data: { user: { id: userId } }, error: null })
        },
        database: db.db
      };
    }

    throw new Error(`Unexpected createClient args: ${JSON.stringify(args)}`);
  };

  const req = new Request('http://localhost/functions/vibescore-device-token-issue', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json', Authorization: `Bearer ${userJwt}` },
    body: JSON.stringify({ device_name: 'test-mac', platform: 'macos' })
  });

  const res = await fn(req);
  assert.equal(res.status, 200);

  const data = await res.json();
  assert.equal(typeof data.device_id, 'string');
  assert.equal(typeof data.token, 'string');

  assert.equal(calls.length, 1, 'expected only one createClient call');

  const deviceInsert = db.inserts.find((i) => i.table === 'vibescore_tracker_devices');
  assert.ok(deviceInsert, 'device insert not performed');
  assert.equal(deviceInsert.rows?.[0]?.user_id, userId);

  const tokenInsert = db.inserts.find((i) => i.table === 'vibescore_tracker_device_tokens');
  assert.ok(tokenInsert, 'token insert not performed');
});

test('vibescore-device-token-issue admin mode skips user lookup', async () => {
  const fn = require('../insforge-functions/vibescore-device-token-issue');

  const calls = [];
  const service = createServiceDbMock();
  const adminUserId = '22222222-2222-2222-2222-222222222222';

  globalThis.createClient = (args) => {
    calls.push(args);
    if (args && args.edgeFunctionToken === SERVICE_ROLE_KEY) {
      return { database: service.db };
    }
    throw new Error(`Unexpected createClient args: ${JSON.stringify(args)}`);
  };

  const req = new Request('http://localhost/functions/vibescore-device-token-issue', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json', Authorization: `Bearer ${SERVICE_ROLE_KEY}` },
    body: JSON.stringify({ user_id: adminUserId, device_name: 'admin-mac', platform: 'macos' })
  });

  const res = await fn(req);
  assert.equal(res.status, 200);

  assert.equal(calls.length, 1, 'expected only service client createClient call in admin mode');

  const deviceInsert = service.inserts.find((i) => i.table === 'vibescore_tracker_devices');
  assert.ok(deviceInsert, 'device insert not performed');
  assert.equal(deviceInsert.rows?.[0]?.user_id, adminUserId);
});

test('vibescore-ingest uses serviceRoleKey as edgeFunctionToken and ingests hourly aggregates', async () => {
  const fn = require('../insforge-functions/vibescore-ingest');

  const calls = [];
  const fetchCalls = [];

  const tokenRow = {
    id: 'token-id',
    user_id: '33333333-3333-3333-3333-333333333333',
    device_id: '44444444-4444-4444-4444-444444444444',
    revoked_at: null
  };

  function from(table) {
    if (table === 'vibescore_tracker_device_tokens') {
      return {
        select: () => ({
          eq: () => ({
            maybeSingle: async () => ({ data: tokenRow, error: null })
          })
        }),
        update: () => ({ eq: async () => ({ error: null }) })
      };
    }

    if (table === 'vibescore_tracker_devices') {
      return {
        update: () => ({ eq: async () => ({ error: null }) })
      };
    }

    throw new Error(`Unexpected table: ${table}`);
  }

  globalThis.createClient = (args) => {
    calls.push(args);
    if (args && args.edgeFunctionToken === SERVICE_ROLE_KEY) {
      return { database: { from } };
    }
    throw new Error(`Unexpected createClient args: ${JSON.stringify(args)}`);
  };

  globalThis.fetch = async (url, init) => {
    fetchCalls.push({ url, init });
    const u = new URL(url);

    if (u.pathname.endsWith('/api/database/records/vibescore_tracker_hourly')) {
      return new Response(JSON.stringify([{ hour_start: '2025-12-17T00:00:00.000Z' }]), {
        status: 201,
        headers: { 'Content-Type': 'application/json' }
      });
    }

    return new Response('not found', { status: 404 });

===== test/init-uninstall.test.js
const assert = require('node:assert/strict');
const os = require('node:os');
const path = require('node:path');
const fs = require('node:fs/promises');
const { test } = require('node:test');

const { cmdInit } = require('../src/commands/init');
const { cmdUninstall } = require('../src/commands/uninstall');

test('init then uninstall restores original Codex notify (when pre-existing notify exists)', async () => {
  const tmp = await fs.mkdtemp(path.join(os.tmpdir(), 'vibescore-init-uninstall-'));
  const prevHome = process.env.HOME;
  const prevCodexHome = process.env.CODEX_HOME;
  const prevToken = process.env.VIBESCORE_DEVICE_TOKEN;
  const prevWrite = process.stdout.write;

  try {
    process.env.HOME = tmp;
    process.env.CODEX_HOME = path.join(tmp, '.codex');
    delete process.env.VIBESCORE_DEVICE_TOKEN;
    await fs.mkdir(process.env.CODEX_HOME, { recursive: true });

    const codexConfigPath = path.join(process.env.CODEX_HOME, 'config.toml');
    const originalNotify = 'notify = ["echo", "hello"]\n';
    await fs.writeFile(codexConfigPath, originalNotify, 'utf8');

    process.stdout.write = () => true;
    await cmdInit(['--no-auth', '--no-open', '--base-url', 'https://example.invalid']);

    const installed = await fs.readFile(codexConfigPath, 'utf8');
    assert.match(installed, /^notify\s*=\s*\[.+\]\s*$/m);
    assert.ok(!installed.includes('["echo", "hello"]'), 'expected init to override notify');

    const cursorsPath = path.join(tmp, '.vibescore', 'tracker', 'cursors.json');
    const cursors = JSON.parse(await fs.readFile(cursorsPath, 'utf8'));
    assert.ok(typeof cursors.updatedAt === 'string' && cursors.updatedAt.length > 0);

    await cmdUninstall([]);

    const restored = await fs.readFile(codexConfigPath, 'utf8');
    assert.ok(restored.includes('notify = ["echo", "hello"]'), 'expected uninstall to restore original notify');

    const notifyHandlerPath = path.join(tmp, '.vibescore', 'bin', 'notify.cjs');
    await assert.rejects(fs.stat(notifyHandlerPath), /ENOENT/);
  } finally {
    process.stdout.write = prevWrite;
    if (prevHome === undefined) delete process.env.HOME;
    else process.env.HOME = prevHome;
    if (prevCodexHome === undefined) delete process.env.CODEX_HOME;
    else process.env.CODEX_HOME = prevCodexHome;
    if (prevToken === undefined) delete process.env.VIBESCORE_DEVICE_TOKEN;
    else process.env.VIBESCORE_DEVICE_TOKEN = prevToken;
    await fs.rm(tmp, { recursive: true, force: true });
  }
});

test('init then uninstall removes notify when none existed', async () => {
  const tmp = await fs.mkdtemp(path.join(os.tmpdir(), 'vibescore-init-uninstall-'));
  const prevHome = process.env.HOME;
  const prevCodexHome = process.env.CODEX_HOME;
  const prevToken = process.env.VIBESCORE_DEVICE_TOKEN;
  const prevWrite = process.stdout.write;

  try {
    process.env.HOME = tmp;
    process.env.CODEX_HOME = path.join(tmp, '.codex');
    delete process.env.VIBESCORE_DEVICE_TOKEN;
    await fs.mkdir(process.env.CODEX_HOME, { recursive: true });

    const codexConfigPath = path.join(process.env.CODEX_HOME, 'config.toml');
    await fs.writeFile(codexConfigPath, '# empty\n', 'utf8');

    process.stdout.write = () => true;
    await cmdInit(['--no-auth', '--no-open', '--base-url', 'https://example.invalid']);

    const installed = await fs.readFile(codexConfigPath, 'utf8');
    assert.match(installed, /^notify\s*=\s*\[.+\]\s*$/m);

    await cmdUninstall([]);

    const restored = await fs.readFile(codexConfigPath, 'utf8');
    assert.ok(!/^notify\s*=.*$/m.test(restored), 'expected uninstall to remove notify when none existed');
  } finally {
    process.stdout.write = prevWrite;
    if (prevHome === undefined) delete process.env.HOME;
    else process.env.HOME = prevHome;
    if (prevCodexHome === undefined) delete process.env.CODEX_HOME;
    else process.env.CODEX_HOME = prevCodexHome;
    if (prevToken === undefined) delete process.env.VIBESCORE_DEVICE_TOKEN;
    else process.env.VIBESCORE_DEVICE_TOKEN = prevToken;
    await fs.rm(tmp, { recursive: true, force: true });
  }
});

===== test/rollout-parser.test.js
const assert = require('node:assert/strict');
const os = require('node:os');
const path = require('node:path');
const fs = require('node:fs/promises');
const { test } = require('node:test');

const { parseRolloutIncremental } = require('../src/lib/rollout');

test('parseRolloutIncremental skips duplicate token_count records (unchanged total_token_usage)', async () => {
  const tmp = await fs.mkdtemp(path.join(os.tmpdir(), 'vibescore-rollout-'));
  try {
    const rolloutPath = path.join(tmp, 'rollout-test.jsonl');
    const queuePath = path.join(tmp, 'queue.jsonl');
    const cursors = { version: 1, files: {}, updatedAt: null };

    const usage1 = {
      input_tokens: 1,
      cached_input_tokens: 0,
      output_tokens: 2,
      reasoning_output_tokens: 0,
      total_tokens: 3
    };
    const usage2 = {
      input_tokens: 1,
      cached_input_tokens: 0,
      output_tokens: 1,
      reasoning_output_tokens: 0,
      total_tokens: 2
    };

    const totals1 = usage1;
    const totals2 = {
      input_tokens: usage1.input_tokens + usage2.input_tokens,
      cached_input_tokens: 0,
      output_tokens: usage1.output_tokens + usage2.output_tokens,
      reasoning_output_tokens: 0,
      total_tokens: usage1.total_tokens + usage2.total_tokens
    };

    const lines = [
      buildTokenCountLine({ ts: '2025-12-17T00:00:00.000Z', last: usage1, total: totals1 }),
      buildTokenCountLine({ ts: '2025-12-17T00:00:01.000Z', last: usage1, total: totals1 }), // duplicate
      buildTokenCountLine({ ts: '2025-12-17T00:00:02.000Z', last: usage2, total: totals2 }),
      buildTokenCountLine({ ts: '2025-12-17T00:00:03.000Z', last: usage2, total: totals2 }) // duplicate
    ];

    await fs.writeFile(rolloutPath, lines.join('\n') + '\n', 'utf8');

    const res = await parseRolloutIncremental({ rolloutFiles: [rolloutPath], cursors, queuePath });
    assert.equal(res.filesProcessed, 1);
    assert.equal(res.eventsAggregated, 2);
    assert.equal(res.bucketsQueued, 1);

    const queued = await readJsonLines(queuePath);
    assert.equal(queued.length, 1);
    assert.equal(
      queued.reduce((sum, ev) => sum + Number(ev.total_tokens || 0), 0),
      usage1.total_tokens + usage2.total_tokens
    );
  } finally {
    await fs.rm(tmp, { recursive: true, force: true });
  }
});

test('parseRolloutIncremental splits usage into half-hour buckets', async () => {
  const tmp = await fs.mkdtemp(path.join(os.tmpdir(), 'vibescore-rollout-'));
  try {
    const rolloutPath = path.join(tmp, 'rollout-test.jsonl');
    const queuePath = path.join(tmp, 'queue.jsonl');
    const cursors = { version: 1, files: {}, updatedAt: null };

    const usage1 = {
      input_tokens: 1,
      cached_input_tokens: 0,
      output_tokens: 0,
      reasoning_output_tokens: 0,
      total_tokens: 1
    };
    const usage2 = {
      input_tokens: 0,
      cached_input_tokens: 0,
      output_tokens: 2,
      reasoning_output_tokens: 0,
      total_tokens: 2
    };

    const lines = [
      buildTokenCountLine({ ts: '2025-12-17T00:10:00.000Z', last: usage1, total: usage1 }),
      buildTokenCountLine({ ts: '2025-12-17T00:40:00.000Z', last: usage2, total: usage2 })
    ];

    await fs.writeFile(rolloutPath, lines.join('\n') + '\n', 'utf8');

    const res = await parseRolloutIncremental({ rolloutFiles: [rolloutPath], cursors, queuePath });
    assert.equal(res.filesProcessed, 1);
    assert.equal(res.eventsAggregated, 2);
    assert.equal(res.bucketsQueued, 2);

    const queued = await readJsonLines(queuePath);
    assert.equal(queued.length, 2);
    const byBucket = new Map(queued.map((row) => [row.hour_start, row]));
    assert.equal(byBucket.size, 2);
    assert.equal(byBucket.get('2025-12-17T00:00:00.000Z')?.total_tokens, usage1.total_tokens);
    assert.equal(byBucket.get('2025-12-17T00:30:00.000Z')?.total_tokens, usage2.total_tokens);
  } finally {
    await fs.rm(tmp, { recursive: true, force: true });
  }
});

test('parseRolloutIncremental handles total_token_usage reset by counting last_token_usage', async () => {
  const tmp = await fs.mkdtemp(path.join(os.tmpdir(), 'vibescore-rollout-'));
  try {
    const rolloutPath = path.join(tmp, 'rollout-test.jsonl');
    const queuePath = path.join(tmp, 'queue.jsonl');
    const cursors = { version: 1, files: {}, updatedAt: null };

    const usageA = {
      input_tokens: 0,
      cached_input_tokens: 0,
      output_tokens: 0,
      reasoning_output_tokens: 0,
      total_tokens: 10
    };
    const usageB = {
      input_tokens: 0,
      cached_input_tokens: 0,
      output_tokens: 0,
      reasoning_output_tokens: 0,
      total_tokens: 5
    };
    const usageReset = {
      input_tokens: 0,
      cached_input_tokens: 0,
      output_tokens: 0,
      reasoning_output_tokens: 0,
      total_tokens: 7
    };

    const totalsA = usageA;
    const totalsB = { ...usageA, total_tokens: usageA.total_tokens + usageB.total_tokens };
    const totalsReset = usageReset; // reset: totals decreased from totalsB.total_tokens

    const lines = [
      buildTokenCountLine({ ts: '2025-12-17T00:00:00.000Z', last: usageA, total: totalsA }),
      buildTokenCountLine({ ts: '2025-12-17T00:00:01.000Z', last: usageB, total: totalsB }),
      buildTokenCountLine({ ts: '2025-12-17T00:00:02.000Z', last: usageReset, total: totalsReset }),
      buildTokenCountLine({ ts: '2025-12-17T00:00:03.000Z', last: usageReset, total: totalsReset }) // duplicate after reset
    ];

    await fs.writeFile(rolloutPath, lines.join('\n') + '\n', 'utf8');

    const res = await parseRolloutIncremental({ rolloutFiles: [rolloutPath], cursors, queuePath });
    assert.equal(res.filesProcessed, 1);
    assert.equal(res.eventsAggregated, 3);
    assert.equal(res.bucketsQueued, 1);

    const queued = await readJsonLines(queuePath);
    assert.equal(queued.length, 1);
    assert.equal(
      queued.reduce((sum, ev) => sum + Number(ev.total_tokens || 0), 0),
      usageA.total_tokens + usageB.total_tokens + usageReset.total_tokens
    );
  } finally {
    await fs.rm(tmp, { recursive: true, force: true });
  }
});

test('parseRolloutIncremental handles total_token_usage reset when last_token_usage is missing', async () => {
  const tmp = await fs.mkdtemp(path.join(os.tmpdir(), 'vibescore-rollout-'));
  try {
    const rolloutPath = path.join(tmp, 'rollout-test.jsonl');
    const queuePath = path.join(tmp, 'queue.jsonl');
    const cursors = { version: 1, files: {}, updatedAt: null };

    const usageA = {
      input_tokens: 0,
      cached_input_tokens: 0,
      output_tokens: 0,
      reasoning_output_tokens: 0,
      total_tokens: 4
    };
    const usageB = {
      input_tokens: 0,
      cached_input_tokens: 0,
      output_tokens: 0,
      reasoning_output_tokens: 0,
      total_tokens: 6
    };

    const totalsA = usageA;
    const totalsB = { ...usageA, total_tokens: usageA.total_tokens + usageB.total_tokens };
    const totalsReset = { ...usageA, total_tokens: 5 };

    const lines = [
      buildTokenCountLine({ ts: '2025-12-17T00:00:00.000Z', last: usageA, total: totalsA }),
      buildTokenCountLine({ ts: '2025-12-17T00:00:01.000Z', last: usageB, total: totalsB }),
      buildTokenCountLine({ ts: '2025-12-17T00:00:02.000Z', last: null, total: totalsReset }),
      buildTokenCountLine({ ts: '2025-12-17T00:00:03.000Z', last: null, total: totalsReset }) // duplicate after reset
    ];

    await fs.writeFile(rolloutPath, lines.join('\n') + '\n', 'utf8');

    const res = await parseRolloutIncremental({ rolloutFiles: [rolloutPath], cursors, queuePath });
    assert.equal(res.filesProcessed, 1);
    assert.equal(res.eventsAggregated, 3);
    assert.equal(res.bucketsQueued, 1);

    const queued = await readJsonLines(queuePath);
    assert.equal(queued.length, 1);
    assert.equal(
      queued.reduce((sum, ev) => sum + Number(ev.total_tokens || 0), 0),
      usageA.total_tokens + usageB.total_tokens + totalsReset.total_tokens
    );
  } finally {
    await fs.rm(tmp, { recursive: true, force: true });
  }
});

test('parseRolloutIncremental handles Every Code token_count envelope', async () => {
  const tmp = await fs.mkdtemp(path.join(os.tmpdir(), 'vibescore-rollout-'));

===== test/status.test.js
const assert = require('node:assert/strict');
const os = require('node:os');
const path = require('node:path');
const fs = require('node:fs/promises');
const { test } = require('node:test');

const { cmdStatus } = require('../src/commands/status');

test('status prints last upload timestamps from upload.throttle.json', async () => {
  const tmp = await fs.mkdtemp(path.join(os.tmpdir(), 'vibescore-status-'));
  const prevHome = process.env.HOME;
  const prevCodexHome = process.env.CODEX_HOME;
  const prevWrite = process.stdout.write;

  try {
    process.env.HOME = tmp;
    process.env.CODEX_HOME = path.join(tmp, '.codex');

    const trackerDir = path.join(tmp, '.vibescore', 'tracker');
    await fs.mkdir(trackerDir, { recursive: true });
    await fs.mkdir(process.env.CODEX_HOME, { recursive: true });

    await fs.writeFile(
      path.join(process.env.CODEX_HOME, 'config.toml'),
      'notify = [\"/usr/bin/env\", \"node\", \"~/.vibescore/bin/notify.cjs\"]\n',
      'utf8'
    );

    await fs.writeFile(
      path.join(trackerDir, 'config.json'),
      JSON.stringify({ baseUrl: 'https://example.invalid', deviceToken: 't', deviceId: 'd' }, null, 2) + '\n',
      'utf8'
    );
    await fs.writeFile(path.join(trackerDir, 'cursors.json'), JSON.stringify({ updatedAt: '2025-12-18T00:00:00.000Z' }) + '\n', 'utf8');
    await fs.writeFile(path.join(trackerDir, 'queue.jsonl'), '', 'utf8');
    await fs.writeFile(path.join(trackerDir, 'queue.state.json'), JSON.stringify({ offset: 0 }) + '\n', 'utf8');

    const lastSuccessMs = 1766053145522; // 2025-12-18T10:19:05.522Z
    const nextAllowedAtMs = lastSuccessMs + 1000;
    await fs.writeFile(
      path.join(trackerDir, 'upload.throttle.json'),
      JSON.stringify({ version: 1, lastSuccessMs, nextAllowedAtMs, backoffUntilMs: 0, backoffStep: 0 }, null, 2) + '\n',
      'utf8'
    );

    let out = '';
    process.stdout.write = (chunk, enc, cb) => {
      out += typeof chunk === 'string' ? chunk : chunk.toString(enc || 'utf8');
      if (typeof cb === 'function') cb();
      return true;
    };

    await cmdStatus();

    assert.match(out, /- Last upload: 2025-12-18T10:19:05\.522Z/);
    assert.match(out, /- Next upload after: 2025-12-18T10:19:06\.522Z/);
  } finally {
    process.stdout.write = prevWrite;
    if (prevHome === undefined) delete process.env.HOME;
    else process.env.HOME = prevHome;
    if (prevCodexHome === undefined) delete process.env.CODEX_HOME;
    else process.env.CODEX_HOME = prevCodexHome;
    await fs.rm(tmp, { recursive: true, force: true });
  }
});

===== test/upload-throttle.test.js
const assert = require('node:assert/strict');
const { test } = require('node:test');

const {
  DEFAULTS,
  normalizeState,
  decideAutoUpload,
  recordUploadSuccess,
  recordUploadFailure,
  parseRetryAfterMs
} = require('../src/lib/upload-throttle');

test('normalizeState tolerates null/invalid values', () => {
  const s = normalizeState({ lastSuccessMs: 'nope', nextAllowedAtMs: -1, backoffUntilMs: 0, backoffStep: '2' });
  assert.equal(s.version, 1);
  assert.equal(s.lastSuccessMs, 0);
  assert.equal(s.nextAllowedAtMs, 0);
  assert.equal(s.backoffUntilMs, 0);
  assert.equal(s.backoffStep, 2);
});

test('decideAutoUpload blocks when no pending bytes', () => {
  const d = decideAutoUpload({ nowMs: 1000, pendingBytes: 0, state: {}, config: null });
  assert.equal(d.allowed, false);
  assert.equal(d.reason, 'no-pending');
});

test('decideAutoUpload blocks until nextAllowedAtMs', () => {
  const nowMs = 1_000_000;
  const d = decideAutoUpload({
    nowMs,
    pendingBytes: 123,
    state: { nextAllowedAtMs: nowMs + 10_000 },
    config: null
  });
  assert.equal(d.allowed, false);
  assert.equal(d.reason, 'throttled');
  assert.equal(d.blockedUntilMs, nowMs + 10_000);
});

test('decideAutoUpload chooses large drain when backlogBytes reached', () => {
  const nowMs = 1_000_000;
  const d = decideAutoUpload({
    nowMs,
    pendingBytes: DEFAULTS.backlogBytes,
    state: { nextAllowedAtMs: 0 },
    config: null
  });
  assert.equal(d.allowed, true);
  assert.equal(d.maxBatches, DEFAULTS.maxBatchesLarge);
  assert.equal(d.batchSize, DEFAULTS.batchSize);
});

test('recordUploadSuccess sets nextAllowedAtMs and resets backoff', () => {
  const nowMs = 10_000;
  const s = recordUploadSuccess({
    nowMs,
    state: { backoffStep: 3, backoffUntilMs: nowMs + 999_999 },
    randInt: () => 0
  });
  assert.equal(s.lastSuccessMs, nowMs);
  assert.equal(s.backoffStep, 0);
  assert.equal(s.backoffUntilMs, 0);
  assert.equal(s.nextAllowedAtMs, nowMs + DEFAULTS.intervalMs);
});

test('recordUploadFailure uses Retry-After for 429', () => {
  const nowMs = 10_000;
  const s = recordUploadFailure({
    nowMs,
    state: { backoffStep: 0, nextAllowedAtMs: 0 },
    error: { status: 429, retryAfterMs: 120_000, message: 'too many requests' }
  });
  assert.equal(s.backoffUntilMs, nowMs + 120_000);
  assert.equal(s.nextAllowedAtMs, nowMs + 120_000);
  assert.equal(s.backoffStep, 1);
  assert.ok(typeof s.lastErrorAt === 'string' && s.lastErrorAt.length > 0);
  assert.ok(typeof s.lastError === 'string' && s.lastError.includes('too many requests'));
});

test('recordUploadFailure exponential backoff on non-429', () => {
  const nowMs = 10_000;
  const s1 = recordUploadFailure({
    nowMs,
    state: { backoffStep: 0, nextAllowedAtMs: 0 },
    error: { status: 500, message: 'server error' }
  });
  const s2 = recordUploadFailure({
    nowMs,
    state: s1,
    error: { status: 500, message: 'server error' }
  });
  assert.equal(s1.backoffUntilMs, nowMs + DEFAULTS.backoffInitialMs);
  assert.equal(s2.backoffUntilMs, nowMs + DEFAULTS.backoffInitialMs * 2);
});

test('parseRetryAfterMs parses seconds and HTTP-date', () => {
  assert.equal(parseRetryAfterMs('2', 1000), 2000);
  const d = new Date(10_000).toUTCString();
  assert.equal(parseRetryAfterMs(d, 0), 10_000);
  assert.equal(parseRetryAfterMs('invalid'), null);
});

===== test/uploader.test.js
const assert = require('node:assert/strict');
const os = require('node:os');
const path = require('node:path');
const fs = require('node:fs/promises');
const { test } = require('node:test');

function stubIngestHourly() {
  const calls = [];
  const apiPath = require.resolve('../src/lib/vibescore-api');
  const original = require.cache[apiPath];
  require.cache[apiPath] = {
    exports: {
      ingestHourly: async ({ hourly }) => {
        calls.push(hourly);
        return { inserted: hourly.length, skipped: 0 };
      }
    }
  };

  const restore = () => {
    if (original) require.cache[apiPath] = original;
    else delete require.cache[apiPath];
  };

  return { calls, restore };
}

test('drainQueueToCloud defaults missing source to codex', async () => {
  const tmp = await fs.mkdtemp(path.join(os.tmpdir(), 'vibescore-uploader-'));
  const queuePath = path.join(tmp, 'queue.jsonl');
  const queueStatePath = path.join(tmp, 'queue.state.json');

  const bucket = {
    hour_start: '2025-12-17T00:00:00.000Z',
    input_tokens: 1,
    cached_input_tokens: 0,
    output_tokens: 2,
    reasoning_output_tokens: 0,
    total_tokens: 3
  };

  await fs.writeFile(queuePath, JSON.stringify(bucket) + '\n', 'utf8');

  const stub = stubIngestHourly();
  try {
    const { drainQueueToCloud } = require('../src/lib/uploader');
    await drainQueueToCloud({
      baseUrl: 'http://localhost',
      deviceToken: 'device-token',
      queuePath,
      queueStatePath,
      maxBatches: 1,
      batchSize: 10
    });

    assert.equal(stub.calls.length, 1);
    assert.equal(stub.calls[0].length, 1);
    assert.equal(stub.calls[0][0].source, 'codex');
  } finally {
    stub.restore();
    await fs.rm(tmp, { recursive: true, force: true });
  }
});

===== test/usage-aggregate.test.js
const assert = require('node:assert/strict');
const { test } = require('node:test');

test('sumDailyRowsToTotals aggregates with BigInt', async () => {
  const mod = await import('../dashboard/src/lib/usage-aggregate.js');
  const sumDailyRowsToTotals = mod.sumDailyRowsToTotals;

  const rows = [
    {
      total_tokens: '9007199254740993',
      input_tokens: '1',
      cached_input_tokens: '0',
      output_tokens: 2,
      reasoning_output_tokens: '0'
    },
    {
      total_tokens: 7,
      input_tokens: '3',
      cached_input_tokens: '1',
      output_tokens: '4',
      reasoning_output_tokens: '2'
    },
    {
      total_tokens: null,
      input_tokens: null,
      cached_input_tokens: null,
      output_tokens: null,
      reasoning_output_tokens: null,
      missing: true
    }
  ];

  const totals = sumDailyRowsToTotals(rows);

  assert.equal(totals.total_tokens, '9007199254741000');
  assert.equal(totals.input_tokens, '4');
  assert.equal(totals.cached_input_tokens, '1');
  assert.equal(totals.output_tokens, '6');
  assert.equal(totals.reasoning_output_tokens, '2');
});

