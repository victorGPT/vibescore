# PR Retrospective: High Review-Cycle Cases (2025-07-13 to 2026-01-13)

## Method
- Scope: closed PRs in the last 6 months (2025-07-13 to 2026-01-13).
- Review cycle definition: review event (CHANGES_REQUESTED/COMMENTED/APPROVED) -> code update commit -> review event.
- Code update detection: commit touches code paths (dashboard/, insforge-functions/, insforge-src/, src/, test/, copy.jsx).
- Selection: top 5 PRs with review cycles >= 3 (merged preferred; no unmerged fallback needed).

## Notes on Review Signal Quality
- Many review events are automated Codex reviews triggered by repeated "@codex review" comments.
- For several PRs, the review bodies do not contain actionable feedback; root causes were inferred from follow-up fix PRs and PR gate notes.
- Recommendation: track "human review cycles" separately (exclude chatgpt-codex-connector) to reduce noise.

## Selected PRs (Top 5)
- #56 (cycles=14) feat: top models module and usage identity alignment (frontend+backend)
- #25 (cycles=9) feat: one-login link code install flow (frontend+backend)
- #55 (cycles=4) Billable total tokens: ingest + backfill + read paths (frontend+backend)
- #34 (cycles=4) refactor(ui): refine matrix dashboard design system (frontend)
- #66 (cycles=3) feat: public view profile identity (frontend+backend)

---

## PR #56: Top models + usage identity alignment

### Problem Theme
Model identity normalization was inconsistent across endpoints and timezones, leading to multiple follow-up fixes for alias timeline handling and filters.

### Evidence
- Follow-up PRs #58-#63: preserve provider prefixes, hourly model filter selection, non-UTC heatmap alias filtering, prefixed model identity (see git history entries for those PRs).
- PR comments reference alias timeline bucketing and missing model columns in raw/hourly paths (recorded in `docs/retrospective/2026-01-13-pr-retro.json`).

### 5 Whys
1. Why were fixes needed after merge? Model identity was inconsistent across daily/hourly/monthly/heatmap endpoints.
2. Why inconsistent? Each endpoint implemented filtering and alias timeline logic separately.
3. Why separate logic? No shared, enforced model identity contract across the usage API surface.
4. Why no shared contract? Design focused on feature delivery (top models) but did not lock cross-endpoint invariants.
5. Why were invariants missed? No checklist or tests asserting identity behavior across all endpoints and timezones.

### Fishbone (Root Cause Categories)
- People: Feature scope pushed ahead of cross-endpoint consistency review.
- Process: No cross-endpoint invariants checklist for identity/filters.
- Tools: Lack of shared helper enforced via tests.
- Requirements: Model identity semantics not formalized for all views.
- Code: Duplicated filter logic per endpoint.
- Tests: Missing regression tests for non-UTC, unfiltered, and prefix cases.
- Communication: Fixes tracked across multiple PRs, increasing coordination overhead.

### Stage Attribution
- Primary: Design
- Secondary: Implementation, Testing

---

## PR #25: One-login link code install flow

### Problem Theme
Cross-layer contract mismatch (gateway RPC paths, idempotency, UI expiry handling) caused multiple fixes after feature launch.

### Evidence
- Fix PRs and docs: `docs/pr/2025-12-29-link-code-exchange-rpc.md`, `docs/pr/2025-12-29-link-code-exchange-records.md`.
- PR gate notes: `docs/pr/2025-12-28-one-login-link-code.md` (uncovered live E2E exchange).

### 5 Whys
1. Why were multiple fixes required? The link code exchange flow failed under real gateway constraints and edge cases.
2. Why did it fail? The initial design assumed RPC endpoints and stable request_id semantics that were not present.
3. Why were assumptions incorrect? Gateway capabilities and idempotency requirements were not validated early.
4. Why not validated? No end-to-end contract test against gateway constraints before merge.
5. Why no contract test? Integration checklist focused on feature delivery, not environment-specific compatibility.

### Fishbone (Root Cause Categories)
- People: Assumptions about gateway exposure not challenged.
- Process: No integration contract gate before merge.
- Tools: Acceptance scripts existed but not run against real gateway.
- Requirements: Idempotency and RPC path constraints underspecified.
- Code: Multiple layers (CLI, edge functions, dashboard) diverged on request_id and expiry.
- Tests: Missing live E2E validation for exchange path.
- Communication: Fixes split into separate PRs, slowing stabilization.

### Stage Attribution
- Primary: Design
- Secondary: Implementation, Testing

---

## PR #55: Billable total tokens rollout

### Problem Theme
Billable totals were introduced, but ordering/aggregation logic remained tied to total tokens, causing UI/API mismatch.

### Evidence
- Low-signal review note flagged sorting by total_tokens; treated as weak evidence.
- Follow-up PR #57: `docs/pr/2026-01-06-usage-hourly-billable.md` (stored billable totals in UTC aggregate + regression tests).

### 5 Whys
1. Why did UI order not match billable totals? API sorting still used total_tokens.
2. Why did API keep old sorting? The rollout updated data fields but not ordering rules everywhere.
3. Why not updated everywhere? No rollout checklist to align API ordering with new metric.
4. Why no checklist? Metrics change treated as data update, not behavior change.
5. Why treated as data-only? Design review did not list derived behaviors (sorting, ranking) as acceptance criteria.

### Fishbone (Root Cause Categories)
- People: Behavioral impacts of new metric underappreciated.
- Process: Rollout checklist missing "ordering/ranking" audit.
- Tools: No static check tying UI ranking to API fields.
- Requirements: Acceptance criteria did not mention ordering alignment.
- Code: Sorting logic hard-coded to total_tokens.
- Tests: Missing regression tests covering ordering by billable_total_tokens.
- Communication: Review feedback came late in the cycle.

### Stage Attribution
- Primary: Implementation
- Secondary: Review, Testing

---

## PR #34: Matrix UI refactor

### Problem Theme
UI refactor introduced layout and interaction regressions (trend hover math, single-point color, header button styles, null mock now handling).

### Evidence
- Follow-up fixes: trend hover width alignment, trend single-point color, header button style restore, heatmap null mock guard (see `git log` UI fix commits around 2025-12-30).
- PR gate notes: `docs/pr/2025-12-30-ui-refactor.md` (no manual live-data verification or cross-browser visual regression).

### 5 Whys
1. Why did UI regressions appear after merge? Layout and interaction rules changed without full regression coverage.
2. Why was coverage insufficient? Visual and cross-browser checks were not executed.
3. Why not executed? Refactor treated as stylistic, not behavior-affecting.
4. Why treated as stylistic? No UI change checklist to flag behavioral impacts (hover math, layout sizing).
5. Why no checklist? Design system refactors lacked guardrails for visual regression.

### Fishbone (Root Cause Categories)
- People: UX edge cases not prioritized under refactor pressure.
- Process: No visual regression or cross-browser gate.
- Tools: No snapshot or layout tests for hover math.
- Requirements: "Refactor" not translated into measurable UI behaviors.
- Code: Layout math duplicated across components.
- Tests: Missing UI regression coverage for hover/axis alignment.
- Communication: Review focused on visuals, not interaction math.

### Stage Attribution
- Primary: Implementation
- Secondary: Testing

---

## PR #66: Public view profile identity

### Problem Theme
Public view profile used incorrect data fields and avatar exposure, requiring post-merge fixes for privacy-safe fields.

### Evidence
- Post-merge fixes: commit `0384edb` (read public profile fields) and `ab632b5` (force pixel avatar in public view).

### 5 Whys
1. Why were privacy fixes needed? Public view reused private profile data fields and avatar rendering.
2. Why reused private fields? Implementation mirrored existing private profile logic.
3. Why was public schema not distinct? Design did not specify public-safe fields and avatar policy.
4. Why not specified? Public view requirements focused on availability, not privacy constraints.
5. Why privacy constraints missing? No "public exposure" checklist for new endpoints.

### Fishbone (Root Cause Categories)
- People: Privacy constraints not explicitly reviewed.
- Process: No public-data exposure gate in design review.
- Tools: Tests did not enforce public field selection.
- Requirements: Public profile schema and avatar rules underspecified.
- Code: Private profile logic reused without filtering.
- Tests: Missing regression tests for public fields/avatars.
- Communication: Privacy implications surfaced post-merge.

### Stage Attribution
- Primary: Design
- Secondary: Implementation, Testing

---

## Frontend Summary (Aggregated)
- Recurring root causes: visual/interaction edge cases untested; UI behavior assumptions not encoded.
- Dominant stages: Implementation and Testing.
- Prevention ideas: visual regression checks for trend/heatmap; UI behavior checklist for refactors.

## Backend Summary (Aggregated)
- Recurring root causes: cross-endpoint contract drift; gateway capability assumptions; privacy/schema gaps.
- Dominant stages: Design and Implementation.
- Prevention ideas: contract checklists for API invariants; gateway compatibility smoke tests; public data exposure gates.

---

## Skill Draft (Concept Only)

### Name
pr-review-cycle-retro

### Description (Trigger)
Use when a repo has recurring review cycles or repeated post-merge fixes and you need a structured, repeatable PR retrospective.

### Inputs
- since (default: 6 months)
- min_review_cycles (default: 3)
- code_paths (default: dashboard/, insforge-functions/, insforge-src/, src/, test/, copy.jsx)
- include_unmerged_fallback (default: true)
- frontend_map / backend_map

### Outputs
- docs/retrospective/YYYY-MM-DD-pr-retro.md
- docs/retrospective/YYYY-MM-DD-pr-retro.csv
- docs/retrospective/YYYY-MM-DD-pr-retro.json

### Workflow
1. Fetch closed PRs in time range.
2. Compute review cycles (review -> code update -> review).
3. Select top N PRs by cycles.
4. Extract review discussion and follow-up fixes.
5. Produce 5 Whys + Fishbone + stage attribution per PR.
6. Aggregate by frontend/backend and list recurring root causes.

### Guardrails
- Flag automated-review-only cycles as low-signal.
- Require at least one evidence item per PR (review note, fix PR, or regression doc).
- Avoid quoting >25 words from any single source.

### Test Scenarios (Skill Validation)
- Scenario A: PRs with only automated reviews -> should flag low-signal.
- Scenario B: PRs with clear CHANGES_REQUESTED -> should extract actionable root causes.
- Scenario C: Mixed frontend/backend PR -> should classify both sides.

---

## Suggestions
- Track human vs automated review cycles separately.
- Add an "invariants checklist" for cross-endpoint features (identity, filtering, ordering).
- Add a "public exposure" checklist for any new public endpoint.
- Require a minimal integration smoke test for gateway-dependent flows.

## Verification (Regression Gate)
- Command: `node scripts/ops/pr-retro.cjs --max-prs 20 --out-dir /tmp/vibeusage-pr-retro-check`
- Result: PASS (script completed; artifacts written to /tmp; 3 PRs met cycle threshold within first 20)
